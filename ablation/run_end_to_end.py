#!/usr/bin/env python3
"""
Run ablation study end-to-end experiments for all repositories.
This script runs end-to-end tests with 5 different cache configurations.

Output structure:
  results/
  ├── end_to_end/
  │   ├── no_cache/
  │   ├── symbol_only/
  │   ├── symbol_loop/
  │   ├── symbol_loop_grid/
  │   └── all_cache/
  └── ablation_end_to_end.csv
"""

import os
import sys
import csv
import subprocess
import shutil
from pathlib import Path
from glob import glob

# Add parent directory to path for imports
SCRIPT_DIR = Path(__file__).parent.absolute()
PROJECT_ROOT = SCRIPT_DIR.parent
sys.path.insert(0, str(PROJECT_ROOT))

# Output directories
RESULTS_DIR = SCRIPT_DIR / "results"
END_TO_END_DIR = RESULTS_DIR / "end_to_end"
CSV_FILENAME = "ablation_end_to_end.csv"

# Configuration names in order
CONFIG_NAMES = ['no_cache', 'symbol_only', 'symbol_loop', 'symbol_loop_grid', 'all_cache']

# Column name mapping (runner.py uses full config key names)
COLUMN_MAPPING = {
    'ablation_no_cache': 'ablation_no_cache',
    'ablation_symbol_only': 'ablation_symbol_only',
    'ablation_symbol_loop': 'ablation_symbol_loop',
    'ablation_symbol_loop_grid': 'ablation_symbol_loop_grid',
    'ablation_all_cache': 'ablation_all_cache'
}


def check_python():
    """Check if Python3 is available (always true if running this script)."""
    return True


def check_triton_sanitizer():
    """Check if triton-sanitizer is available in PATH."""
    return shutil.which("triton-sanitizer") is not None


def prompt_continue():
    """Prompt user to continue or abort."""
    try:
        response = input("Continue? (y/n) ").strip().lower()
        return response in ('y', 'yes')
    except (EOFError, KeyboardInterrupt):
        print()
        return False


def check_whitelists():
    """Check for whitelist files and print status."""
    print("Checking for whitelists...")

    whitelist_files = {
        "utils/liger_kernel_whitelist.txt": "Liger-Kernel whitelist detected (27 tests)",
        "utils/flag_gems_whitelist.txt": "FlagGems whitelist detected (20 tests)",
        "utils/tritonbench_whitelist.txt": "TritonBench whitelist detected (64 files)",
    }

    found_any = False
    for filepath, message in whitelist_files.items():
        full_path = PROJECT_ROOT / filepath
        if full_path.exists():
            print(f"  * {message}")
            found_any = True

    if not found_any:
        print("  No whitelists found, will run all tests")

    print()


def print_header():
    """Print script header."""
    print("=" * 40)
    print("Running Ablation Study End-to-End Tests")
    print("=" * 40)
    print()


def print_configuration_info():
    """Print configuration explanation."""
    print("Ablation Study Cache Configurations:")
    print("  Testing cache configurations (symbol, loop, grid, kernel):")
    print("    1. no_cache:          (0, 0, 0, 0)")
    print("    2. symbol_only:       (1, 0, 0, 0)")
    print("    3. symbol_loop:       (1, 1, 0, 0)")
    print("    4. symbol_loop_grid:  (1, 1, 1, 0)")
    print("    5. all_cache:         (1, 1, 1, 1)")
    print()
    print("Repositories: Liger-Kernel, FlagGems, TritonBench")
    print()
    print(f"Output directory: {RESULTS_DIR}")
    print(f"Logs directory:   {END_TO_END_DIR}")
    print(f"CSV file:         {RESULTS_DIR / CSV_FILENAME}")
    print()


def run_tests():
    """Run all tests using runner.py."""
    print("=" * 40)
    print("Starting Tests")
    print("=" * 40)
    print()

    runner_script = PROJECT_ROOT / "runner.py"

    cmd = [
        sys.executable,
        str(runner_script),
        "--repos", "all",
        "--config-groups", "ablation_studies",
        "--output-dir", str(END_TO_END_DIR),
    ]

    result = subprocess.run(cmd, cwd=str(PROJECT_ROOT))
    return result.returncode


def find_runner_csv():
    """Find the CSV file generated by runner.py."""
    # Look for results_*.csv in the output directory
    pattern = str(END_TO_END_DIR / "results_*.csv")
    csv_files = glob(pattern)

    if not csv_files:
        return None

    # Return the most recent one
    csv_files.sort(key=os.path.getmtime, reverse=True)
    return Path(csv_files[0])


def extract_ablation_columns(runner_csv_path):
    """
    Extract only ablation columns from runner's CSV and save to new CSV.

    Args:
        runner_csv_path: Path to the runner-generated CSV file

    Returns:
        Path to the new CSV file or None on error
    """
    if not runner_csv_path or not runner_csv_path.exists():
        print("No runner CSV file found")
        return None

    print(f"Reading results from: {runner_csv_path}")

    # Read the runner's CSV
    rows = []
    with open(runner_csv_path, 'r', newline='', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        original_fieldnames = reader.fieldnames

        for row in reader:
            rows.append(row)

    if not rows:
        print("No data in runner CSV")
        return None

    # Define output columns
    output_columns = ['Test_Name'] + list(COLUMN_MAPPING.keys())

    # Check which columns exist in the source
    available_columns = []
    for col in COLUMN_MAPPING.keys():
        if col in original_fieldnames:
            available_columns.append(col)
        else:
            print(f"Warning: Column '{col}' not found in runner CSV")

    if not available_columns:
        print("No ablation columns found in runner CSV")
        return None

    # Prepare output data
    csv_data = []
    for row in rows:
        test_name = row.get('Test_Name', '')
        if not test_name:
            continue

        output_row = {'Test_Name': test_name}
        for col in COLUMN_MAPPING.keys():
            output_row[col] = row.get(col, 'N/A')

        csv_data.append(output_row)

    # Write the new CSV
    csv_path = RESULTS_DIR / CSV_FILENAME
    try:
        with open(csv_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=output_columns)
            writer.writeheader()
            writer.writerows(csv_data)

        print(f"\nCSV exported to: {csv_path}")
        print(f"  Total tests: {len(csv_data)}")

        return csv_path
    except Exception as e:
        print(f"\nError exporting CSV: {e}")
        return None


def print_summary(csv_path):
    """Print summary statistics from the CSV."""
    if not csv_path or not csv_path.exists():
        return

    print()
    print("=" * 40)
    print("SUMMARY")
    print("=" * 40)

    # Read the CSV and calculate statistics
    with open(csv_path, 'r', newline='', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        rows = list(reader)

    for col in COLUMN_MAPPING.keys():
        passed = 0
        failed = 0
        total_time = 0.0

        for row in rows:
            value = row.get(col, 'N/A')
            if value not in ('N/A', 'FAILED', 'TIMEOUT', 'ERROR', ''):
                try:
                    total_time += float(value)
                    passed += 1
                except ValueError:
                    failed += 1
            else:
                failed += 1

        config_name = col.replace('ablation_', '')
        print(f"  {config_name:20s}: {passed:3d} passed, {failed:3d} failed, total time: {total_time:>10.2f}s")

    # Calculate speedups
    baseline_times = []
    all_cache_times = []

    for row in rows:
        baseline_val = row.get('ablation_no_cache', 'N/A')
        all_cache_val = row.get('ablation_all_cache', 'N/A')

        try:
            baseline = float(baseline_val)
            all_cache = float(all_cache_val)
            if baseline > 0 and all_cache > 0:
                baseline_times.append(baseline)
                all_cache_times.append(all_cache)
        except ValueError:
            continue

    if baseline_times and all_cache_times:
        total_baseline = sum(baseline_times)
        total_all_cache = sum(all_cache_times)
        if total_all_cache > 0:
            speedup = total_baseline / total_all_cache
            print()
            print(f"  Overall speedup (no_cache vs all_cache): {speedup:.2f}x")

    print()


def print_results(csv_path):
    """Print final results and status."""
    if csv_path:
        print()
        print("=" * 40)
        print("Analysis Complete!")
        print("=" * 40)
        print()
        print("Results:")
        print(f"  CSV File:  {csv_path}")
        print(f"  Log files: {END_TO_END_DIR}/*/")
        print()
    else:
        print()
        print(f"Warning: CSV generation failed, but test logs are available in {END_TO_END_DIR}/")
        print()

    print("=" * 40)


def main():
    """Main entry point."""
    print_header()

    if not check_python():
        print("Error: Python3 is not installed or not in PATH")
        sys.exit(1)

    if not check_triton_sanitizer():
        print("Warning: triton-sanitizer not found in PATH")
        print("Make sure triton-sanitizer is installed and available in PATH")
        if not prompt_continue():
            print("Aborted.")
            sys.exit(1)

    # Create output directories
    RESULTS_DIR.mkdir(parents=True, exist_ok=True)
    END_TO_END_DIR.mkdir(parents=True, exist_ok=True)

    check_whitelists()
    print_configuration_info()

    # Run tests
    test_exit_code = run_tests()

    print()
    print("=" * 40)
    print("Test Runs Complete")
    print("=" * 40)
    print()
    print(f"Results saved in: {END_TO_END_DIR}/")
    print()

    # Extract ablation columns and generate CSV
    print("=" * 40)
    print("Generating Ablation CSV")
    print("=" * 40)
    print()

    runner_csv = find_runner_csv()
    csv_path = extract_ablation_columns(runner_csv)

    print_summary(csv_path)
    print_results(csv_path)

    sys.exit(0 if csv_path else 1)


if __name__ == "__main__":
    main()
